{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8bd6aaf",
   "metadata": {},
   "source": [
    "# Diabetes Readmission Prediction Pipeline Execution\n",
    "\n",
    "This notebook provides a convenient interface to execute the `src/run.py` pipeline script directly from within the `src/` directory.\n",
    "\n",
    "The `src/run.py` script is designed to be run as a Python module using `python -m src.run <args>` from the *project's root directory* (the directory containing the `src/` folder). This ensures that Python correctly resolves module paths and relative imports (like `from . import config`).\n",
    "\n",
    "Executing `src/run.py` directly (e.g., `python run.py`) from within `src/` or running `python -m src.run` from within `src/` can lead to `ImportError` issues because the script is not run in the correct package context.\n",
    "\n",
    "To address this, this notebook uses Python's `subprocess` module to execute the `python -m src.run` command, explicitly setting the current working directory (`cwd`) to the project root. This accurately simulates the intended command-line execution environment.\n",
    "\n",
    "The notebook is structured into several cells:\n",
    "1.  **Environment Setup:** Imports necessary libraries, determines the project root path, and defines a helper function `run_src_script` to handle execution via `subprocess`.\n",
    "2.  **Default Execution:** Runs the pipeline with default configuration (equivalent to `$ python -m src.run`).\n",
    "3.  **Force Train Autoencoder:** Runs the pipeline forcing autoencoder retraining (equivalent to `$ python -m src.run --train-ae`).\n",
    "4.  **Force Train Predictor:** Runs the pipeline forcing predictor retraining (equivalent to `$ python -m src.run --train-predictor`).\n",
    "5.  **Force Train Both:** Runs the pipeline forcing both autoencoder and predictor retraining (equivalent to `$ python -m src.run --train-ae --train-predictor`).\n",
    "\n",
    "Execute the cells sequentially or individually as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13145a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Setting up execution environment ---\n",
      "Current notebook directory: c:\\Users\\aflon\\OneDrive\\Documentos\\GitHub\\IDSS-for-Diabetes-Readmission-Prediction\\src\n",
      "Target execution directory (project root): c:\\Users\\aflon\\OneDrive\\Documentos\\GitHub\\IDSS-for-Diabetes-Readmission-Prediction\n",
      "Project structure confirmed ('src' found in root).\n",
      "Log files will be saved in: c:\\Users\\aflon\\OneDrive\\Documentos\\GitHub\\IDSS-for-Diabetes-Readmission-Prediction\\logs\n",
      "Execution helper ready.\n",
      "Setup complete. Helper function 'run_src_script' is defined and ready.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 1: Environment Setup and Execution Helper ---\n",
    "# Imports, path configuration, and a helper function for running the script.\n",
    "# This cell sets up the necessary environment and defines the `run_src_script`\n",
    "# helper function which executes the main pipeline script.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "print(\"--- Setting up execution environment ---\")\n",
    "\n",
    "# Get the directory where this notebook file is located.\n",
    "# In most Jupyter/IPython environments, this is the current working directory.\n",
    "notebook_dir = os.getcwd()\n",
    "print(f\"Current notebook directory: {notebook_dir}\")\n",
    "\n",
    "# The project root is the parent directory of the 'src' directory.\n",
    "# We assume this notebook is located directly within the 'src' directory.\n",
    "# Use abspath to get the absolute path and handle '..' correctly.\n",
    "project_root_dir = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "\n",
    "print(f\"Target execution directory (project root): {project_root_dir}\")\n",
    "\n",
    "# Define the directory where logs will be saved (as configured in src/config.py)\n",
    "# Using os.path.join makes paths cross-platform compatible.\n",
    "# Note: We explicitly create the logs directory here in the notebook setup\n",
    "# as the script might be run without preprocessing, but the logging happens always.\n",
    "log_dir = os.path.join(project_root_dir, 'logs') # Should match config.LOGS_DIR\n",
    "\n",
    "# Optional but recommended: Verify that the 'src' directory exists at the calculated root.\n",
    "src_path_check = os.path.join(project_root_dir, 'src')\n",
    "if not os.path.isdir(src_path_check):\n",
    "    print(f\"ERROR: The 'src' directory was not found at the calculated project root '{project_root_dir}'.\")\n",
    "    print(\"Please ensure this notebook file is located directly within your project's 'src' directory.\")\n",
    "    # In a production script, you might sys.exit(1) here. In a notebook, printing an error is usually sufficient.\n",
    "else:\n",
    "    print(\"Project structure confirmed ('src' found in root).\")\n",
    "    # Create the logs directory if it doesn't exist. exist_ok=True prevents errors if it exists.\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    print(f\"Log files will be saved in: {log_dir}\")\n",
    "    print(\"Execution helper ready.\")\n",
    "\n",
    "\n",
    "def run_src_script(args: list[str]):\n",
    "    \"\"\"\n",
    "    Executes the src/run.py script as a Python module from the project root.\n",
    "\n",
    "    This function constructs and runs the command `python -m src.run`\n",
    "    with the given arguments using subprocess, setting the working directory\n",
    "    to the project root. Captured stdout/stderr are also saved to a\n",
    "    timestamped log file in the 'logs' directory.\n",
    "\n",
    "    The underlying src/run.py script is enhanced to accept command-line arguments\n",
    "    matching hyperparameters defined in src/config.py (e.g., --ae-epochs,\n",
    "    --hidden-dim, --use-gru). Pass these arguments as strings in the `args` list.\n",
    "\n",
    "    Examples of `args` lists:\n",
    "    []                                     # Default execution\n",
    "    ['--train-ae']                         # Force AE training\n",
    "    ['--ae-epochs', '100']                 # Override AE epochs\n",
    "    ['--hidden-dim', '256', '--use-gru']   # Override model dimension and use GRU\n",
    "    ['--train-predictor', '--predictor-learning-rate', '0.0001'] # Force predictor training with custom LR\n",
    "\n",
    "    Args:\n",
    "        args: A list of strings representing command-line arguments\n",
    "              to pass to src/run.py. Each argument and its value (if any)\n",
    "              should be a separate string in the list.\n",
    "              E.g., ['--arg1', 'value1', '--flag2', 'value2']\n",
    "    \"\"\"\n",
    "    # Construct the full command list for subprocess\n",
    "    command = [sys.executable, '-m', 'src.run'] + args\n",
    "    # Create a string representation of the command for logging/printing\n",
    "    command_str = ' '.join(command)\n",
    "\n",
    "    # Generate a timestamp for the log file to ensure uniqueness per run\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    # Create the full path for the log file\n",
    "    log_filename = f\"pipeline_run_{timestamp}.log\"\n",
    "    log_filepath = os.path.join(log_dir, log_filename)\n",
    "\n",
    "    print(f\"\\n--- Executing Command ---\")\n",
    "    print(f\"Working Directory: {project_root_dir}\")\n",
    "    print(f\"Command: {command_str}\")\n",
    "    print(f\"Saving output to log file: {log_filepath}\")\n",
    "    print(\"---------------------------\")\n",
    "\n",
    "    # Variables to hold captured output and execution status\n",
    "    stdout_output = \"\"\n",
    "    stderr_output = \"\"\n",
    "    execution_status = \"UNKNOWN\" # Initial status\n",
    "\n",
    "    # Use a try...except...finally block to ensure logging and reporting\n",
    "    # happen even if the subprocess fails or an error occurs during execution.\n",
    "    try:\n",
    "        # Open the log file in write mode ('w') with UTF-8 encoding.\n",
    "        # This creates a new file for each run or overwrites if the timestamp isn't unique enough (very unlikely).\n",
    "        with open(log_filepath, 'w', encoding='utf-8') as log_file:\n",
    "            # Write initial information to the log file\n",
    "            log_file.write(f\"--- Pipeline Execution Log - {timestamp} ---\\n\")\n",
    "            log_file.write(f\"Working Directory: {project_root_dir}\\n\")\n",
    "            log_file.write(f\"Command: {command_str}\\n\")\n",
    "            log_file.write(\"-\" * 30 + \"\\n\\n\") # Separator\n",
    "\n",
    "            # Run the subprocess.\n",
    "            # `capture_output=True` captures stdout/stderr.\n",
    "            # `text=True` decodes stdout/stderr bytes into strings using 'encoding'.\n",
    "            # `encoding='utf-8'` specifies the encoding for decoding.\n",
    "            # `errors='replace'` replaces characters that cannot be decoded with a placeholder.\n",
    "            # `check=True` raises CalledProcessError if the command returns a non-zero exit status.\n",
    "            result = subprocess.run(\n",
    "                command,\n",
    "                cwd=project_root_dir,\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                encoding='utf-8',\n",
    "                errors='replace',\n",
    "                check=True\n",
    "            )\n",
    "\n",
    "            # If subprocess.run completes without CalledProcessError, it was a success (from subprocess perspective)\n",
    "            stdout_output = result.stdout\n",
    "            stderr_output = result.stderr\n",
    "            execution_status = \"SUCCESS\"\n",
    "\n",
    "            # Write captured stdout and stderr to the log file\n",
    "            log_file.write(\"--- STDOUT ---\\n\")\n",
    "            log_file.write(stdout_output)\n",
    "            log_file.write(\"\\n\") # Ensure newline after stdout\n",
    "\n",
    "            if stderr_output:\n",
    "                 log_file.write(\"--- STDERR ---\\n\")\n",
    "                 log_file.write(stderr_output)\n",
    "                 log_file.write(\"\\n\")\n",
    "\n",
    "            log_file.write(\"-\" * 30 + \"\\n\") # Separator\n",
    "            log_file.write(\"--- COMMAND EXECUTED SUCCESSFULLY ---\\n\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # Handle the case where the Python executable is not found in the environment\n",
    "        execution_status = \"ERROR - Python Not Found\"\n",
    "        error_msg = f\"Error: Python executable '{sys.executable}' not found.\\nPlease ensure Python is installed and accessible in your environment (check your PATH).\"\n",
    "        print(f\"\\n--- EXECUTION ERROR ---\")\n",
    "        print(error_msg)\n",
    "        print(\"---------------------------\")\n",
    "\n",
    "        # Write error details to log file (using 'a' mode to append)\n",
    "        with open(log_filepath, 'a', encoding='utf-8') as log_file:\n",
    "             log_file.write(f\"\\n--- ERROR --- {execution_status}\\n\")\n",
    "             log_file.write(error_msg + \"\\n\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        # Handle errors where the subprocess itself exited with a non-zero status\n",
    "        execution_status = f\"ERROR - Command Failed (Return Code: {e.returncode})\"\n",
    "        print(f\"\\n--- COMMAND FAILED ---\")\n",
    "        print(f\"Command: {command_str}\")\n",
    "        print(f\"Working Directory: {project_root_dir}\")\n",
    "        print(f\"Return Code: {e.returncode}\")\n",
    "        # Print captured output to console even on failure, as they might contain error messages\n",
    "        print(f\"\\nSTDOUT:\\n{e.stdout}\")\n",
    "        print(f\"\\nSTDERR:\\n{e.stderr}\")\n",
    "        print(\"---------------------------\")\n",
    "\n",
    "        # Write captured output and error details to log file (using 'a' mode to append)\n",
    "        with open(log_filepath, 'a', encoding='utf-8') as log_file:\n",
    "             log_file.write(f\"\\n--- ERROR --- {execution_status}\\n\")\n",
    "             log_file.write(f\"Command: {command_str}\\n\")\n",
    "             log_file.write(f\"Working Directory: {project_root_dir}\\n\")\n",
    "             log_file.write(f\"Return Code: {e.returncode}\\n\")\n",
    "             log_file.write(\"\\nSTDOUT:\\n\")\n",
    "             log_file.write(e.stdout)\n",
    "             log_file.write(\"\\nSTDERR:\\n\")\n",
    "             log_file.write(e.stderr)\n",
    "             log_file.write(\"\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any other unexpected exceptions during the execution setup or subprocess handling\n",
    "        execution_status = f\"ERROR - Unexpected Exception: {type(e).__name__}\"\n",
    "        error_msg = f\"An unexpected error occurred during execution: {e}\"\n",
    "        print(f\"\\n--- UNEXPECTED ERROR DURING EXECUTION ---\")\n",
    "        print(error_msg)\n",
    "        print(\"---------------------------\")\n",
    "\n",
    "        # Write error details to log file (using 'a' mode to append)\n",
    "        with open(log_filepath, 'a', encoding='utf-8') as log_file:\n",
    "             log_file.write(f\"\\n--- ERROR --- {execution_status}\\n\")\n",
    "             log_file.write(error_msg + \"\\n\")\n",
    "\n",
    "    finally:\n",
    "       # This block executes regardless of whether an exception occurred or not\n",
    "       print(f\"\\n--- Execution finished with status: {execution_status} ---\")\n",
    "       print(f\"Full output saved to: {log_filepath}\")\n",
    "       print(\"\\n\") # Add a newline for separation between executions\n",
    "\n",
    "\n",
    "# Final confirmation message after the setup cell has run\n",
    "print(\"Setup complete. Helper function 'run_src_script' is defined and ready.\")\n",
    "print(\"You can now use this function in subsequent cells by passing lists of strings\")\n",
    "print(\"corresponding to the desired command-line arguments for src/run.py.\")\n",
    "print(\"For example: run_src_script(args=['--train-ae', '--ae-epochs', '50', '--hidden-dim', '256', '--no-use-gru'])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "257be404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running pipeline with default configuration ---\n",
      "\n",
      "--- Executing Command ---\n",
      "Working Directory: c:\\Users\\aflon\\OneDrive\\Documentos\\GitHub\\IDSS-for-Diabetes-Readmission-Prediction\n",
      "Command: c:\\Users\\aflon\\OneDrive\\Documentos\\GitHub\\IDSS-for-Diabetes-Readmission-Prediction\\.venv\\Scripts\\python.exe -m src.run\n",
      "Saving output to log file: c:\\Users\\aflon\\OneDrive\\Documentos\\GitHub\\IDSS-for-Diabetes-Readmission-Prediction\\logs\\pipeline_run_20250519_101707.log\n",
      "---------------------------\n",
      "\n",
      "--- Execution finished with status: SUCCESS ---\n",
      "Full output saved to: c:\\Users\\aflon\\OneDrive\\Documentos\\GitHub\\IDSS-for-Diabetes-Readmission-Prediction\\logs\\pipeline_run_20250519_101707.log\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Execute with Default Settings\n",
    "\n",
    "# This cell runs the pipeline using the default configuration settings\n",
    "# specified within the src/config.py file.\n",
    "# This simulates the command:\n",
    "# $ python -m src.run\n",
    "\n",
    "print(\"--- Running pipeline with default configuration ---\")\n",
    "run_src_script(args=[]) # Pass an empty list as no command-line arguments are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7be88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execute Forcing Autoencoder Retraining\n",
    "\n",
    "# This cell runs the pipeline and explicitly requests that the\n",
    "# Autoencoder model be retrained, overriding the default configuration\n",
    "# or any existing saved model.\n",
    "# This simulates the command:\n",
    "# $ python -m src.run --train-ae\n",
    "\n",
    "print(\"--- Running pipeline forcing Autoencoder training ---\")\n",
    "run_src_script(args=['--train-ae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421c4268",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execute Forcing Predictor Retraining\n",
    "\n",
    "# This cell runs the pipeline and explicitly requests that the\n",
    "# Predictor model be retrained, overriding the default configuration\n",
    "# or any existing saved model.\n",
    "# This simulates the command:\n",
    "# $ python -m src.run --train-predictor\n",
    "\n",
    "print(\"--- Running pipeline forcing Predictor training ---\")\n",
    "run_src_script(args=['--train-predictor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64d7d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execute Forcing Both AE and Predictor Retraining\n",
    "\n",
    "# This cell runs the pipeline and explicitly requests that *both*\n",
    "# the Autoencoder and the Predictor models be retrained.\n",
    "# This simulates the command:\n",
    "# $ python -m src.run --train-ae --train-predictor\n",
    "\n",
    "print(\"--- Running pipeline forcing both AE and Predictor training ---\")\n",
    "run_src_script(args=['--train-ae', '--train-predictor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b1af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execute Forcing AE Retraining with Custom Hyperparameters\n",
    "\n",
    "# This cell runs the pipeline, forcing the Autoencoder to be retrained,\n",
    "# and overrides its number of epochs and learning rate.\n",
    "# This simulates a command like:\n",
    "# $ python -m src.run --train-ae --ae-epochs 50 --ae-learning-rate 0.0005\n",
    "\n",
    "print(\"--- Running pipeline forcing AE training with custom epochs and learning rate ---\")\n",
    "custom_ae_args = [\n",
    "    '--train-ae',             # Force training the AE\n",
    "    '--ae-epochs', '50',       # Override AE_EPOCHS to 50\n",
    "    '--ae-learning-rate', '0.0005' # Override AE_LEARNING_RATE to 0.0005 (pass float as string)\n",
    "]\n",
    "run_src_script(args=custom_ae_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211fa8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execute Forcing Predictor Retraining with Custom Hyperparameters\n",
    "\n",
    "# This cell runs the pipeline, forcing the Predictor to be retrained,\n",
    "# and overrides its batch size and optimizer.\n",
    "# This simulates a command like:\n",
    "# $ python -m src.run --train-predictor --predictor-batch-size 128 --predictor-optimizer Adam\n",
    "\n",
    "print(\"--- Running pipeline forcing Predictor training with custom batch size and optimizer ---\")\n",
    "custom_predictor_args = [\n",
    "    '--train-predictor',      # Force training the Predictor\n",
    "    '--predictor-batch-size', '128', # Override PREDICTOR_BATCH_SIZE to 128\n",
    "    '--predictor-optimizer', 'Adam' # Override PREDICTOR_OPTIMIZER to 'Adam'\n",
    "]\n",
    "run_src_script(args=custom_predictor_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1999b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execute Forcing Both Retraining and Tuning Model Architecture\n",
    "\n",
    "# This cell runs the pipeline, forces retraining of *both* AE and Predictor,\n",
    "# and overrides key model architecture parameters: hidden dimension,\n",
    "# number of RNN layers, dropout, and switches to using GRU instead of LSTM (if default is LSTM).\n",
    "# This simulates a command like:\n",
    "# $ python -m src.run --train-ae --train-predictor --hidden-dim 256 --num-rnn-layers 2 --dropout 0.3 --use-gru\n",
    "\n",
    "print(\"--- Running pipeline forcing both training and tuning model architecture ---\")\n",
    "architecture_tuning_args = [\n",
    "    '--train-ae',             # Force AE training (architecture change affects AE)\n",
    "    '--train-predictor',      # Force Predictor training (architecture change affects Predictor)\n",
    "    '--hidden-dim', '256',    # Override HIDDEN_DIM to 256\n",
    "    '--num-rnn-layers', '2',  # Override NUM_RNN_LAYERS to 2\n",
    "    '--dropout', '0.3',       # Override DROPOUT to 0.3 (pass float as string)\n",
    "    '--use-gru',              # Override USE_GRU to True\n",
    "    '--no-use-attention'      # Override USE_ATTENTION to False (if you want to disable attention)\n",
    "    # Or just omit --no-use-attention to keep default USE_ATTENTION from config/CLI if not overridden\n",
    "]\n",
    "run_src_script(args=architecture_tuning_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051f52d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execute Forcing Both Retraining and Tuning Batch Sizes and Data Workers\n",
    "\n",
    "# This cell runs the pipeline, forces retraining of *both* AE and Predictor,\n",
    "# and overrides the batch size for both training phases and the number\n",
    "# of data loader workers.\n",
    "# This simulates a command like:\n",
    "# $ python -m src.run --train-ae --train-predictor --ae-batch-size 128 --predictor-batch-size 128 --dataloader-num-workers 4\n",
    "\n",
    "print(\"--- Running pipeline forcing both training and tuning batch sizes/data workers ---\")\n",
    "batch_size_tuning_args = [\n",
    "    '--train-ae',             # Force AE training\n",
    "    '--train-predictor',      # Force Predictor training\n",
    "    '--ae-batch-size', '128', # Override AE_BATCH_SIZE to 128\n",
    "    '--predictor-batch-size', '128', # Override PREDICTOR_BATCH_SIZE to 128\n",
    "    '--dataloader-num-workers', '4' # Override DATALOADER_NUM_WORKERS to 4\n",
    "]\n",
    "run_src_script(args=batch_size_tuning_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
