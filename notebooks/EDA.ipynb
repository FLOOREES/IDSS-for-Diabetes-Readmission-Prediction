{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cargamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/diabetic_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estudio inicial de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# los tipos de dato de cada columna\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analisis columna weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analisis_valores(columna):\n",
    "\n",
    "    # Ignorar valores faltantes de la columna original para el conteo\n",
    "    mask_no_na = ~columna.isna()\n",
    "    \n",
    "    # Convertir a numérico, forzando errores a NaN\n",
    "    numeros = pd.to_numeric(columna, errors='coerce')\n",
    "    \n",
    "    # Conteo de valores numéricos y no numéricos (excluyendo nulos originales)\n",
    "    count_numericos = numeros[mask_no_na].notna().sum()\n",
    "    count_no_numericos = mask_no_na.sum() - count_numericos\n",
    "    \n",
    "    # Obtener los valores no numéricos:\n",
    "    no_numericos_series = columna[mask_no_na][numeros[mask_no_na].isna()]\n",
    "    valores_no_numericos = no_numericos_series.unique().tolist()\n",
    "    \n",
    "    # Calcular porcentaje de cada valor único no numérico\n",
    "    conteo_unicos = no_numericos_series.value_counts()\n",
    "    porcentaje_no_numericos = (conteo_unicos / conteo_unicos.sum() * 100).to_dict()\n",
    "    \n",
    "    # Calcular media y desviación estándar para los valores numéricos\n",
    "    media_numericos = numeros[mask_no_na].dropna().mean()\n",
    "    std_numericos = numeros[mask_no_na].dropna().std()\n",
    "    \n",
    "    return {\n",
    "        \"numericos\": count_numericos,\n",
    "        \"no_numericos\": count_no_numericos,\n",
    "        \"porcentaje_no_numericos\": porcentaje_no_numericos,\n",
    "        \"media_numericos\": media_numericos,\n",
    "        \"std_numericos\": std_numericos\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analisis_valores(df['weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cambiar ID a objetos y no numeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change wrong data types\n",
    "df['admission_type_id'] = df['admission_type_id'].astype(str)\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].astype(str)\n",
    "df['admission_source_id'] = df['admission_source_id'].astype(str)\n",
    "df['encounter_id'] = df['encounter_id'].astype(str)\n",
    "df['patient_nbr'] = df['patient_nbr'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def estudio_dataset(df, exclude_columns=None):\n",
    "    \"\"\"\n",
    "    Realiza un estudio de las columnas de un dataset.\n",
    "\n",
    "    Para columnas numéricas, genera un resumen descriptivo (con información adicional sobre valores faltantes).\n",
    "    Para columnas categóricas, muestra los valores únicos, el porcentaje de cada valor y la cantidad de faltantes.\n",
    "\n",
    "    Parámetros:\n",
    "        df (pd.DataFrame): Dataset a analizar.\n",
    "        exclude_columns (list, opcional): Lista de nombres de columnas a excluir del análisis.\n",
    "\n",
    "    Retorna:\n",
    "        dict: Diccionario donde cada clave es el nombre de la columna (no excluida) y el valor es un diccionario\n",
    "              con el estudio realizado para esa columna.\n",
    "    \"\"\"\n",
    "    resultados = {}\n",
    "    exclude_columns = exclude_columns or []\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col in exclude_columns:\n",
    "            continue\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            # Estudio para columnas numéricas\n",
    "            resumen = df[col].describe()\n",
    "            missing = df[col].isnull().sum()\n",
    "            resumen_dict = resumen.to_dict()\n",
    "            resumen_dict['missing'] = missing\n",
    "            resultados[col] = {\n",
    "                'tipo': 'numérica',\n",
    "                'estudio': resumen_dict\n",
    "            }\n",
    "        else:\n",
    "            # Estudio para columnas categóricas\n",
    "            missing = df[col].isnull().sum()\n",
    "            unique_values = df[col].dropna().unique().tolist()\n",
    "            porcentajes = df[col].value_counts(normalize=True, dropna=True) * 100\n",
    "            resultados[col] = {\n",
    "                'tipo': 'categórica',\n",
    "                'unique_values': unique_values,\n",
    "                'porcentajes': porcentajes.to_dict(),\n",
    "                'missing': missing\n",
    "            }\n",
    "    return resultados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estudio_dataset(df, exclude_columns=['encounter_id', 'patient_nbr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNIVARIATE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def univariate_analysis_grid(df):\n",
    "    \"\"\"\n",
    "    Genera un grid de plots univariados para todas las columnas del DataFrame.\n",
    "    \n",
    "    Para cada columna:\n",
    "      - Si es numérica: genera un histograma.\n",
    "      - Si es categórica: genera un gráfico de barras con el conteo de cada categoría.\n",
    "    \n",
    "    Los plots se organizan en un grid de 3 columnas por fila.\n",
    "    \n",
    "    Parámetros:\n",
    "        df (pd.DataFrame): Dataset a analizar.\n",
    "    \"\"\"\n",
    "    num_cols = len(df.columns)\n",
    "    cols_per_row = 3\n",
    "    rows = math.ceil(num_cols / cols_per_row)\n",
    "    \n",
    "    # Crear el grid de subplots\n",
    "    fig = make_subplots(rows=rows, cols=cols_per_row, subplot_titles=df.columns)\n",
    "    \n",
    "    # Iterar por cada columna del DataFrame\n",
    "    for i, col in enumerate(df.columns):\n",
    "        row = i // cols_per_row + 1\n",
    "        col_idx = i % cols_per_row + 1\n",
    "        \n",
    "        # Si la columna es numérica, usamos histograma\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            fig_tmp = px.histogram(df, x=col, title=f'Histograma de {col}')\n",
    "        else:\n",
    "            # Para columnas categóricas: contar valores\n",
    "            count_df = df[col].value_counts().reset_index()\n",
    "            count_df.columns = [col, 'Frecuencia']\n",
    "            fig_tmp = px.bar(count_df, x=col, y='Frecuencia', title=f'Conteo de {col}')\n",
    "        \n",
    "        # Agregar las trazas del plot temporal al subplot correspondiente\n",
    "        for trace in fig_tmp.data:\n",
    "            fig.add_trace(trace, row=row, col=col_idx)\n",
    "    \n",
    "    # Ajustar layout del grid\n",
    "    fig.update_layout(height=rows * 400, width=1200, title_text=\"Análisis Univariado - Grid de Plots\")\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_analysis_grid(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bivariate analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "def analisis_numerico(df):\n",
    "    \"\"\"\n",
    "    Función que recibe un DataFrame de pandas y genera un análisis bivariante\n",
    "    utilizando una matriz de diagramas de dispersión (pair plot) para las columnas numéricas.\n",
    "    Se ajustan los ángulos de las etiquetas para que no se solapen.\n",
    "    \"\"\"\n",
    "    # Seleccionar únicamente las columnas numéricas\n",
    "    columnas_numericas = df.select_dtypes(include=['number']).columns\n",
    "    if len(columnas_numericas) < 2:\n",
    "        print(\"El DataFrame debe tener al menos dos columnas numéricas para realizar un análisis bivariante.\")\n",
    "        return\n",
    "\n",
    "    # Crear la matriz de diagramas de dispersión\n",
    "    fig = px.scatter_matrix(\n",
    "        df,\n",
    "        dimensions=columnas_numericas,\n",
    "        title=\"Análisis Bivariante\",\n",
    "        labels={col: col for col in columnas_numericas}\n",
    "    )\n",
    "\n",
    "    # Ajustar el tamaño del gráfico y márgenes\n",
    "    fig.update_layout(width=1300, height=1300, margin=dict(l=100, r=100, t=100, b=100))\n",
    "    \n",
    "    # Ajustar los ángulos de las etiquetas de cada eje para evitar solapamientos\n",
    "    fig.for_each_xaxis(lambda axis: axis.update(tickangle=0))\n",
    "    fig.for_each_yaxis(lambda axis: axis.update(tickangle=90))\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "def matriz_correlacion(df):\n",
    "    \"\"\"\n",
    "    Función que recibe un DataFrame de pandas y genera una matriz de correlación\n",
    "    visualizada con un heatmap de Plotly.\n",
    "    \"\"\"\n",
    "    # Seleccionar solo columnas numéricas\n",
    "    df_numerico = df.select_dtypes(include=['number'])\n",
    "\n",
    "    if df_numerico.shape[1] < 2:\n",
    "        print(\"El DataFrame debe tener al menos dos columnas numéricas para calcular la correlación.\")\n",
    "        return\n",
    "    \n",
    "    # Calcular la matriz de correlación\n",
    "    corr_matrix = df_numerico.corr()\n",
    "\n",
    "    # Crear el heatmap con Plotly\n",
    "    fig = px.imshow(\n",
    "        corr_matrix,\n",
    "        text_auto=\".2f\",  # Muestra valores con 2 decimales\n",
    "        labels=dict(color=\"Correlación\"),\n",
    "        title=\"Matriz de Correlación\",\n",
    "        color_continuous_scale=\"RdBu_r\"  # Escala de colores para correlaciones positivas y negativas\n",
    "    )\n",
    "\n",
    "    # Ajustar la visualización\n",
    "    fig.update_layout(width=700, height=600)\n",
    "    fig.show()\n",
    "\n",
    "    \"\"\"\n",
    "    Función que recibe un DataFrame de pandas y genera un análisis bivariante para\n",
    "    las columnas categóricas, mostrando para cada par una tabla de contingencia\n",
    "    en forma de heatmap agrupados de dos en dos en una misma figura.\n",
    "    \n",
    "    Parámetros:\n",
    "      - df: DataFrame de pandas.\n",
    "      - excluir: lista de columnas a excluir del análisis (opcional).\n",
    "    \"\"\"\n",
    "    # Seleccionar columnas categóricas\n",
    "    columnas_categoricas = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    # Excluir las columnas indicadas (si las hay)\n",
    "    if excluir is not None:\n",
    "        columnas_categoricas = [col for col in columnas_categoricas if col not in excluir]\n",
    "    \n",
    "    if len(columnas_categoricas) < 2:\n",
    "        print(\"El DataFrame debe tener al menos dos columnas categóricas (después de excluir) para realizar un análisis bivariante.\")\n",
    "        return\n",
    "    \n",
    "    # Lista para almacenar la información de cada par (columna1, columna2, tabla de contingencia)\n",
    "    pares = []\n",
    "    \n",
    "    # Generar los pares de columnas y sus respectivas tablas de contingencia\n",
    "    for i in range(len(columnas_categoricas)):\n",
    "        for j in range(i+1, len(columnas_categoricas)):\n",
    "            col1 = columnas_categoricas[i]\n",
    "            col2 = columnas_categoricas[j]\n",
    "            print(f\"Analizando relación entre '{col1}' y '{col2}'\")\n",
    "            \n",
    "            # Copiar y reemplazar los valores nulos por '?'\n",
    "            df_temp = df[[col1, col2]].copy()\n",
    "            df_temp[col1] = df_temp[col1].fillna(\"?\")\n",
    "            df_temp[col2] = df_temp[col2].fillna(\"?\")\n",
    "            \n",
    "            # Generar la tabla de contingencia\n",
    "            tabla_contingencia = pd.crosstab(df_temp[col1], df_temp[col2], dropna=False)\n",
    "            \n",
    "            if tabla_contingencia.empty:\n",
    "                print(f\"La tabla de contingencia para {col1} y {col2} está vacía.\")\n",
    "                continue\n",
    "            \n",
    "            pares.append((col1, col2, tabla_contingencia))\n",
    "    \n",
    "    # Agrupar los heatmaps de 2 en 2\n",
    "    por_figura = 2\n",
    "    for idx in range(0, len(pares), por_figura):\n",
    "        grupo = pares[idx:idx+por_figura]\n",
    "        ncols = len(grupo)\n",
    "        \n",
    "        # Crear una figura con subplots\n",
    "        fig = make_subplots(rows=1, cols=ncols,\n",
    "                            subplot_titles=[f\"Tabla de contingencia: {p[0]} vs {p[1]}\" for p in grupo])\n",
    "        \n",
    "        # Agregar cada heatmap al subplot correspondiente\n",
    "        for k, (col1, col2, tabla_contingencia) in enumerate(grupo, start=1):\n",
    "            # Extraer datos para el heatmap\n",
    "            z = tabla_contingencia.values\n",
    "            x = list(tabla_contingencia.columns)\n",
    "            y = list(tabla_contingencia.index)\n",
    "            \n",
    "            heatmap = go.Heatmap(\n",
    "                z=z,\n",
    "                x=x,\n",
    "                y=y,\n",
    "                text=z,\n",
    "                texttemplate=\"%{text}\",\n",
    "                colorscale='Viridis'\n",
    "            )\n",
    "            fig.add_trace(heatmap, row=1, col=k)\n",
    "            # Actualizar etiquetas de cada subplot\n",
    "            fig.update_xaxes(title_text=col2, row=1, col=k)\n",
    "            fig.update_yaxes(title_text=col1, row=1, col=k)\n",
    "        \n",
    "        fig.update_layout(height=500, width=600*ncols, title_text=\"Heatmaps de Tablas de Contingencia (2 en 2)\")\n",
    "        fig.show()\n",
    "\n",
    "\n",
    "    \n",
    "    # Iterar sobre cada par de variables categóricas y graficar la tabla de contingencia\n",
    "    for i in range(len(columnas_categoricas)):\n",
    "        for j in range(i+1, len(columnas_categoricas)):\n",
    "            col1 = columnas_categoricas[i]\n",
    "            col2 = columnas_categoricas[j]\n",
    "\n",
    "            print(f\"Analizando relación entre '{col1}' y '{col2}'\")\n",
    "            \n",
    "            # Copiar y reemplazar los valores nulos por un símbolo (por ejemplo, '?')\n",
    "            df_temp = df[[col1, col2]].copy()\n",
    "            df_temp[col1] = df_temp[col1].fillna(\"?\")\n",
    "            df_temp[col2] = df_temp[col2].fillna(\"?\")\n",
    "            \n",
    "            # Generar la tabla de contingencia, sin eliminar categorías nulas\n",
    "            tabla_contingencia = pd.crosstab(df_temp[col1], df_temp[col2], dropna=False)\n",
    "            \n",
    "            if tabla_contingencia.empty:\n",
    "                print(f\"La tabla de contingencia para {col1} y {col2} está vacía.\")\n",
    "                continue\n",
    "            \n",
    "            # Crear el heatmap utilizando plotly.express.imshow\n",
    "            fig = px.imshow(\n",
    "                tabla_contingencia,\n",
    "                text_auto=True,\n",
    "                labels=dict(x=col2, y=col1, color=\"Cuenta\"),\n",
    "                title=f\"Tabla de contingencia: {col1} vs {col2}\"\n",
    "            )\n",
    "            fig.update_layout(width=600, height=500)\n",
    "            fig.show()\n",
    "\n",
    "def analisis_categorico(df, excluir=None):\n",
    "    \"\"\"\n",
    "    Función que recibe un DataFrame de pandas y genera un análisis bivariante para\n",
    "    las columnas categóricas, mostrando para cada par una tabla de contingencia\n",
    "    en forma de heatmap agrupados de dos en dos en una misma figura.\n",
    "    \n",
    "    Parámetros:\n",
    "      - df: DataFrame de pandas.\n",
    "      - excluir: lista de columnas a excluir del análisis (opcional).\n",
    "    \"\"\"\n",
    "    # Seleccionar columnas categóricas\n",
    "    columnas_categoricas = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    # Excluir las columnas indicadas (si las hay)\n",
    "    if excluir is not None:\n",
    "        columnas_categoricas = [col for col in columnas_categoricas if col not in excluir]\n",
    "    \n",
    "    if len(columnas_categoricas) < 2:\n",
    "        print(\"El DataFrame debe tener al menos dos columnas categóricas (después de excluir) para realizar un análisis bivariante.\")\n",
    "        return\n",
    "    \n",
    "    # Lista para almacenar la información de cada par (columna1, columna2, tabla de contingencia)\n",
    "    pares = []\n",
    "    \n",
    "    # Generar los pares de columnas y sus respectivas tablas de contingencia\n",
    "    for i in range(len(columnas_categoricas)):\n",
    "        for j in range(i+1, len(columnas_categoricas)):\n",
    "            col1 = columnas_categoricas[i]\n",
    "            col2 = columnas_categoricas[j]\n",
    "            \n",
    "            # Copiar y reemplazar los valores nulos por '?'\n",
    "            df_temp = df[[col1, col2]].copy()\n",
    "            df_temp[col1] = df_temp[col1].fillna(\"?\")\n",
    "            df_temp[col2] = df_temp[col2].fillna(\"?\")\n",
    "            \n",
    "            # Generar la tabla de contingencia\n",
    "            tabla_contingencia = pd.crosstab(df_temp[col1], df_temp[col2], dropna=False)\n",
    "            \n",
    "            if tabla_contingencia.empty:\n",
    "                print(f\"La tabla de contingencia para {col1} y {col2} está vacía.\")\n",
    "                continue\n",
    "            \n",
    "            pares.append((col1, col2, tabla_contingencia))\n",
    "    \n",
    "    # Agrupar los heatmaps de 2 en 2\n",
    "    por_figura = 2\n",
    "    for idx in range(0, len(pares), por_figura):\n",
    "        grupo = pares[idx:idx+por_figura]\n",
    "        ncols = len(grupo)\n",
    "        \n",
    "        # Crear una figura con subplots\n",
    "        fig = make_subplots(rows=1, cols=ncols,\n",
    "                            subplot_titles=[f\"Tabla de contingencia: {p[0]} vs {p[1]}\" for p in grupo])\n",
    "        \n",
    "        # Agregar cada heatmap al subplot correspondiente\n",
    "        for k, (col1, col2, tabla_contingencia) in enumerate(grupo, start=1):\n",
    "            # Extraer datos para el heatmap\n",
    "            z = tabla_contingencia.values\n",
    "            x = list(tabla_contingencia.columns)\n",
    "            y = list(tabla_contingencia.index)\n",
    "            \n",
    "            heatmap = go.Heatmap(\n",
    "                z=z,\n",
    "                x=x,\n",
    "                y=y,\n",
    "                text=z,\n",
    "                texttemplate=\"%{text}\",\n",
    "                colorscale='Viridis'\n",
    "            )\n",
    "            fig.add_trace(heatmap, row=1, col=k)\n",
    "            # Actualizar etiquetas de cada subplot\n",
    "            fig.update_xaxes(title_text=col2, row=1, col=k)\n",
    "            fig.update_yaxes(title_text=col1, row=1, col=k)\n",
    "        \n",
    "        fig.update_layout(height=500, width=600*ncols, title_text=\"Heatmaps de Tablas de Contingencia (2 en 2)\")\n",
    "        fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analisis_numerico(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_correlacion(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analisis_categorico(df, excluir=['encounter_id', 'patient_nbr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Get the value counts of patient_nbr\n",
    "patient_counts = df['patient_nbr'].value_counts().reset_index()\n",
    "patient_counts.columns = ['patient_nbr', 'counts']\n",
    "\n",
    "patient_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df con solo pacientes que tienen pacient_nbr 23199021\n",
    "filtered_df = df[df['patient_nbr'] == '23199021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeping = ['encounter_id', 'patient_nbr', 'number_emergency', 'number_inpatient', 'number_outpatient', 'time_in_hospital', 'admission_type_id']\n",
    "\n",
    "filtered_df[keeping]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
