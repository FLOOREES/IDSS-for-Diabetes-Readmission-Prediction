{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline for diabetes readmission prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/diabetic_data_no_na_diag.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift evolutive variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['patient_nbr', 'encounter_id'])\n",
    "\n",
    "last_vars = [\n",
    "    'diag_1',\n",
    "    'diag_2',\n",
    "    'diag_3',\n",
    "\n",
    "    'metformin',\n",
    "    'repaglinide',\n",
    "    'nateglinide',\n",
    "    'chlorpropamide',\n",
    "    'glimepiride',\n",
    "    'acetohexamide',\n",
    "    'glipizide',\n",
    "    'glyburide',\n",
    "    'tolbutamide',\n",
    "    'pioglitazone',\n",
    "    'rosiglitazone',\n",
    "    'acarbose',\n",
    "    'miglitol',\n",
    "    'troglitazone',\n",
    "    'tolazamide',\n",
    "    'insulin',\n",
    "    'glyburide-metformin',\n",
    "    'glipizide-metformin',\n",
    "    'glimepiride-pioglitazone',\n",
    "    'metformin-rosiglitazone',\n",
    "    'metformin-pioglitazone',\n",
    "]\n",
    "\n",
    "renamed_last_vars = ['last_' + v for v in last_vars]\n",
    "df.loc[:, renamed_last_vars] = df.loc[:, last_vars].shift()\n",
    "# Previous diagnoses during first encounters are managed later\n",
    "df.loc[:, renamed_last_vars[:3]][df.patient_nbr != df.patient_nbr.shift()] = pd.NA\n",
    "# The previous medication is set to 0 (NO)\n",
    "df.loc[:, renamed_last_vars[3:]][df.patient_nbr != df.patient_nbr.shift()] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop irrelevant and identifier data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\n",
    "    'encounter_id', \n",
    "    'patient_nbr',\n",
    "    'discharge_disposition_id',\n",
    "    'admission_source_id'\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vars = [c for c in df.columns if 'num' in c]\n",
    "x = df[count_vars].to_numpy()\n",
    "x = (x - x.min(0)) / (x.max(0) - x.min(0)) * 1000 + 1\n",
    "df[count_vars] = np.log(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode diagnosis labels and cast to matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_vars = [c for c in df.columns if 'diag_' in c]\n",
    "target_var = 'readmitted'\n",
    "other_vars = [c for c in df.columns if c not in label_vars + [target_var]]\n",
    "others = df[other_vars].to_numpy()\n",
    "labels = df[label_vars].to_numpy()\n",
    "y = df[target_var].to_numpy()\n",
    "\n",
    "label_to_emb = np.load('data/diag_embeddings.npy')\n",
    "label_nans = np.isnan(labels)\n",
    "labels[label_nans] = 0\n",
    "embeddings = label_to_emb[labels.astype('int')]\n",
    "embeddings[label_nans] = np.nan\n",
    "embeddings = embeddings.reshape(embeddings.shape[0], -1)\n",
    "\n",
    "X = np.concatenate([others, embeddings], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplify task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (y > 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data and discard data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "s = X_train.std(0) > 0\n",
    "X_train, X_test = X_train[:, s], X_test[:, s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missings to center\n",
    "We do not exclude NA in order not to exclude patients' first visits\\\n",
    "There are none in y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.nan_to_num(X_train, nan=0)\n",
    "X_test = np.nan_to_num(X_test, nan=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce dimensionality and uncorrelate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.95)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "0.6231984696818825\n",
      "Test\n",
      "0.6219243770143856\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "reg = LogisticRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "print('Train')\n",
    "print(reg.score(X_train, y_train))\n",
    "print('Test')\n",
    "print(reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nilma\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\nilma\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.723756616529532\n",
      "Test\n",
      "0.5733432906218064\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print('Train')\n",
    "print(knn.score(X_train, y_train))\n",
    "print('Test')\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "1.0\n",
      "Test\n",
      "0.5444933574404528\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "print('Train')\n",
    "print(dt.score(X_train, y_train))\n",
    "print('Test')\n",
    "print(dt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "0.6231591635658509\n",
      "Test\n",
      "0.6216099363257606\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "print('Train')\n",
    "print(svm.score(X_train, y_train))\n",
    "print('Test')\n",
    "print(svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "1.0\n",
      "Test\n",
      "0.6101721562770223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print('Train')\n",
    "print(rf.score(X_train, y_train))\n",
    "print('Test')\n",
    "print(rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "0.6896389078140559\n",
      "Test\n",
      "0.6030579356968792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nilma\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print('Train')\n",
    "print(mlp.score(X_train, y_train))\n",
    "print('Test')\n",
    "print(mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Es perd bastanta informació relativa a la medicació ja que majoirtàriament no es recepten i per tant no es pot entrenar el model perquè aprengui a utilitzar aquesta informació. Un bon enfocament seria conseguir representacions significatives de les madicacions.\\\n",
    "Com a punt de partida, funcionen millor mètodes senzills de classificació lineal com la regressió logística i SVM lineal. El punt de partida serà aquest 62% d'accuracy (tenint en compte la simplificació de la tasca), i queda clar que els models avançats s'hauràn d'ajustar i regularitzar amb cura per millorar els resultats."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
